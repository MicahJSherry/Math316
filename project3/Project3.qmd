---
title: "Wind Dashboard - Project 3 | Phase 1"
format:
  dashboard:
    theme: yeti
    pages: true
    orientation: columns
    embed-resources: true
    standalone: true
---

# Overview
::: {.panel-tabset}

## Comparative Wind Patterns Across U.S. Regions
Exploring wind data using the Meteostat

**Group Members:** Travis, Ira, Micah

**Course:** Data Science 

**Goal:** Use ML models to predict wind trends in distinct U.S. regions 

:::
---

# Data & Methods
::: {.panel-tabset}

## Data Source
**Source:** [Meteostat Python API](https://dev.meteostat.net/python/daily.html)  

**Dataset Type:** Aggregated weather observations per station  

**Key Variables**

- `wspd`: Average wind speed (mph)  
- `wdir`: Mean wind direction (degrees)  

**Time Period:** 2024  

**Models:** Wind Speed, Wind Direction, Locations  

**Frame:** Hourly and Daily  

:::
---

# Condition Code Classifier

::: {.panel-tabset}

## Overview

### **Model Objective**
This model predicts weather condition codes using an extensive batch of features.

### **Condition Code Classifications**
- **Clear**: Condition codes 1-2 (Fair weather, clear skies)
- **Cloudy**: Condition codes 3-6 (Cloudy, overcast, foggy conditions)  
- **Rain**: Condition codes 7-13, 17-20 (Various precipitation types including drizzle, rain, thunderstorms)
- **Snow**: Condition codes 14-16, 21-22 (Snow, sleet, freezing precipitation)

*Note: Storm conditions (codes 23-27) were excluded due to extreme rarity in the dataset*

### **Model Construction**
- **Algorithm**: **XGBoost Classifier** (selected after comparison with Random Forest and Logistic Regression)
- **City-based splitting** 40 training cities tested blindly on 10 test cities
- **Features**: **172 engineered features** including:
  - **Interaction terms**: Temperature-pressure ratios, wind-humidity products
  - **Lag features**: 1, 2, and 3-hour historical weather data
  - **Differential terms**: Pressure changes, humidity changes, wind speed variations
  - **Meteorological indices**: Heat index, wind chill, vapor pressure deficit
  - **Temporal features**: Seasonal cycles, solar elevation, daylight indicators
- **Manual class weights** applied to address rain/snow underperformance:
  - Clear: 1.0x | Cloudy: 1.25x | **Rain: 10.0x** | **Snow: 500.0x**
  - This weighting strategy improved Rain and Snow detection rates but slightly reduced overall accuracy

## Confusion Matrix

```{python}
#| echo: false
from models import weather_classification_model

# Generate confusion matrix visualization
confusion_chart = weather_classification_model(visual_type="confusion_matrix")
confusion_chart
```

## Top Features

```{python}
#| echo: false
from models import weather_classification_model

# Generate feature importance visualization
feature_chart = weather_classification_model(visual_type="feature_importance")
feature_chart
```

## Test Cities

```{python}
#| echo: false
from models import weather_classification_model

# Generate geographic performance visualization
geo_chart = weather_classification_model(visual_type="geographic_performance")
geo_chart
```

:::

---

# Wind Speed Model
::: {.panel-tabset}

## Linear Regression & HistGradientBoostingRegressor Models
```{python}

import pandas as pd
import numpy as np
from meteostat import Stations, Hourly
import datetime

# ML imports
from sklearn.model_selection import TimeSeriesSplit, cross_val_score
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import HistGradientBoostingRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer

start = datetime.datetime(2024, 1, 1)
end   = datetime.datetime(2024, 12, 31)

print("Using Pittsburgh station")

stations = (
    Stations()
    .nearby(40.4406, -79.9959)
    .fetch(10)
)

df = pd.DataFrame()
selected_station = None

for station_id in stations.index:
    attempt = Hourly(station_id, start, end).fetch()

    if len(attempt) > 0:
        df = attempt
        selected_station = station_id
        break
    else:
        print("No data availbable")

print("\nMissing Values")
print(df.isna().sum())

df["hour"] = df.index.hour
df["month"] = df.index.month

df["wspd_lag1"] = df["wspd"].shift(1)
df["wspd_lag3"] = df["wspd"].shift(3)
df["wspd_lag6"] = df["wspd"].shift(6)

df = df.dropna(subset=["wspd", "wspd_lag1", "wspd_lag3", "wspd_lag6"])

print("\nLagged 1, 3, and 6 hours before")

feature_cols = [
    "temp", "dwpt", "pres", "rhum", "wdir",
    "hour", "month",
    "wspd_lag1", "wspd_lag3", "wspd_lag6"
]

X = df[feature_cols]
y = df["wspd"]

preprocessor = ColumnTransformer(
    transformers=[
        ("num", Pipeline([
            ("impute", SimpleImputer(strategy="mean")),
            ("scale", StandardScaler())
        ]), feature_cols)
    ]
)

linear_model = Pipeline([
    ("prep", preprocessor),
    ("lr", LinearRegression())
])

boost_model = Pipeline([
    ("prep", preprocessor),
    ("hgb", HistGradientBoostingRegressor(
        max_depth=5,
        learning_rate=0.05
    ))
])

n_splits = min(5, max(2, len(df) // 500))

print(f"\nTimeSeriesSplit with n_splits = {n_splits}")
tscv = TimeSeriesSplit(n_splits=n_splits)


def evaluate(model, name):
    mae = -cross_val_score(model, X, y, cv=tscv, scoring="neg_mean_absolute_error").mean()
    rmse = np.sqrt(-cross_val_score(model, X, y, cv=tscv, scoring="neg_mean_squared_error").mean())
    r2 = cross_val_score(model, X, y, cv=tscv, scoring="r2").mean()

    print(f"\n{name}")
    print(f"MAE:  {mae:.3f}")
    print(f"RMSE: {rmse:.3f}")
    print(f"R²:   {r2:.3f}")

evaluate(linear_model, "Linear Regression")
evaluate(boost_model, "HistGradientBoostingRegressor")

```
:::

---

# Predicting Wind Direction
::: {.panel-tabset}
## Training & Results

**5 cities examined**

Chicago, Denver, Miami, Phoenix, Seattle

**Target Variable**

Wind direction (degrees)

**Training features**

- **Numerical:** temp, dwpt, rhum, pres, wpsd, latitude, longitude, elevation  
- **Categorical:** City  
- **Modified:** hour_sin(N), hour_cos(N), month_sin(N), month_cos(N), condition_group(C)  
- **Excluded:** tsun, snow, wpgt, prcp

**Model Procedures**

- Hourly data sample from 2020-2024 on all cities  
- 80% train/20% test random split  
- StandardScaler() used on Numerical values  
- OneHotEncoder() used on Categorical values

**Results**

- Linear Regression Model: R² = 0.329  
- HistGradientBoosting Model: R² = 0.631  

*See visuals for further model comparisons

:::

---

# Greater Pittsburgh International Airport
::: {.panel-tabset}

## Overview

The features used to predict the weather are the wind speed and direction for the following weather stations:

- Allegheny County Airport
- Butler / Brownsdale
- Washington / Lagonda
- Zelienople / Old Furnace
-  Beaver Falls / West Mayfield

the values we are trying to predict is the wind speed and direction for Greater Pittsburgh International Airport

the model got the folowing metrics on the test set.      

- R²: 0.620057846963885
- RMSE: 54.6469878681952

see the last code cell to see a visualization of the predicted vs actual wind speed.

potential improvements:

- convert wind vector from angle and speed to its north-south and east-west components.
- change more complex model.
- predict more locations (given there closest stations)
- add more features

:::

---

# Visuals

::: {.panel-tabset}

## Pittsburgh Area Model

```{python}
#| echo: false
from models import get_data, train_model, visualize_predictions

data, stations = get_data()
station_test, y_test, y_pred = train_model(data)

chart = visualize_predictions(station_test, y_test, y_pred, stations)
chart
```

## Wind Direction Model

```{python}
#| echo: false
from models import make_wind_model_charts

charts = make_wind_model_charts()
charts
```

:::

---

# Research Questions

::: {.panel-tabset}

## Key Questions

1. How do wind patterns change by region?  
2. What are some case studies of extreme weather?  
3. How do geographical features (lakes, oceans, mountains, deserts, plains) impact wind patterns?

:::  
